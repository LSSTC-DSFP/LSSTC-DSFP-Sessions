{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8cf1f4-94d9-49cb-897e-d1950178a146",
   "metadata": {},
   "source": [
    "## Tips & techniques \n",
    "\n",
    "Profiling and optimizing code is a very broad subject, full of rabbit holes. The more you get into it the more you find out how much more you can optmize and how much better your tests could be done. It's also important to understand when to stop.\n",
    "\n",
    "Careful to not fall into the over optimizing trap!\n",
    "\n",
    "If you intend to open source your code, clarity might be much more relevant than squeezing every drop of performance of your scripts.\n",
    "\n",
    "In this notebook I share a few things I picked up learning about scientific software performance. These were written with the Python scientific development context in mind. If you're doing something different like profiling web environment, for example, they might be completely irrelevant and several things might be very different. Use seu bom senso to guess which tips are relevant for each context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed7104-4fc1-4a4b-a234-24431e69d413",
   "metadata": {},
   "source": [
    "#### #1 Generators are faster than list comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a75c0-58e4-41ae-9d02-b33814e715b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "comp = [i for i in range(10000)]\n",
    "gen = (i for i in range(10000))\n",
    "\n",
    "#gives size for list comprehension\n",
    "x = getsizeof(comp)\n",
    "print(\"x = \", x)\n",
    "\n",
    "#gives size for generator expression\n",
    "y = getsizeof(gen)\n",
    "print(\"y = \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4a989-795a-4515-9e29-a406bf6708b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List Comprehension:\n",
    "import timeit\n",
    "\n",
    "print(timeit.timeit('''list_com = [i for i in range(100) if i % 2 == 0]''', number=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1187a008-2e89-4305-b4c3-4c068a57e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator Expression:\n",
    "import timeit\n",
    "\n",
    "print(timeit.timeit('''gen_exp = (i for i in range(100) if i % 2 == 0)''', number=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04dfb6-9cda-48b4-9765-f226931efe05",
   "metadata": {},
   "source": [
    "The generator yields one item at a time and generates item only when in demand. Whereas, in a list comprehension, Python reserves memory for the whole list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef9c18-7855-40b0-ba6c-4ebf8085e143",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### #2 Between `dict`, `list` and `set`, pick `set` for speed\n",
    "\n",
    "If you can't use `set`s the next best thing might be a `dict`, depending on your user case. The following table can be found on the [Fluent Python](https://www.fluentpython.com) website:\n",
    "\n",
    "<br>\n",
    "\n",
    "len of array | dict time | set time | list time\n",
    "-------------|-----------|----------|----------\n",
    "1.000|0.099ms|0.107ms|9.115ms|\n",
    "10.000|0.109ms|0.119ms|78.219ms|\n",
    "100.000|0.156ms|0.147ms|767.975ms|\n",
    "1.000.000|0.372ms|0.264ms|8.020.312ms|\n",
    "10.000.000|0.512ms|0.330ms|78.558.771ms|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90effd06-f8c2-4dd1-be70-4bbea31d60a9",
   "metadata": {},
   "source": [
    "#### #3 Use `tuple` as Immutable Lists\n",
    "\n",
    "The Python interpreter and standard library make extensive use of tuples as immutable lists, and so should you. This brings two key benefits:\n",
    "\n",
    "- Clarity: When you see a tuple in code, you know its length will never change.\n",
    "- Performance: A tuple uses less memory than a list of the same length, and it allows Python to do some optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f894ef1a-1626-40b8-b542-d08f15095dec",
   "metadata": {},
   "source": [
    "#### #4 Chained comparisons are good\n",
    "\n",
    "When comparing three variables with each other, instead of doing `x < y and y < z`, you can use `x < y < z`.\n",
    "This should prove easier to read (more natural) and faster to run.\n",
    "\n",
    "#### #5 When possible, sort by the key\n",
    "\n",
    "When doing a custom sort on a list, try not to sort using a comparison function. Instead, when possible, sort by the key. This is because the key function will be called only once per item, whereas the comparison function will be called several times per item during the process. \n",
    "\n",
    "#### #6 Sorting can be very costly, learn about the main algorithms\n",
    "\n",
    "[Here](https://realpython.com/sorting-algorithms-python/)'s a recommended source to learn about Python's implementation on some common algorithms.\n",
    "If you prefer a more in depth approach, check the chapter on sorting of Introduction to Algorithms (Cormen, et al.).\n",
    "\n",
    "#### #7 Sampling\n",
    "\n",
    "Even if you have a lot of data, there might not be much advantage from using all of it. By sampling intelligently you might be able to derive the same insight from a much more manageable subset.\n",
    "\n",
    "#### #8 I/O is very costly\n",
    "\n",
    "- For compression youâ€™ll probably find that you drop gzip and bz2, and embrace newer systems like lz4, snappy, and Z-Standard that provide better performance and random access.\n",
    "- For storage formats you may find that you want self-describing formats that are optimized for random access, metadata storage, and binary encoding like Parquet, ORC, Zarr, HDF5, and GeoTIFF.\n",
    "- When working on the cloud you may find that some older formats like HDF5 may not work as well.\n",
    "- You may want to partition or chunk your data in ways that align well to common queries. In Dask DataFrame this might mean choosing a column to sort by for fast selection and joins. For Dask Array this might mean choosing chunk sizes that are aligned with your access patterns and algorithms.\n",
    "\n",
    "#### #9 Your OS is providing you with an unstable environment\n",
    "\n",
    "On top of everything you need to think about you also have to take into consideration that every little pertubation in your OS is like the clap of the wings of a butterfly. There are some softwares that might help you to minimize these interferences.\n",
    "\n",
    "- [Tuna](https://linux.web.cern.ch/mrg/2/Tuna_User_Guide/)\n",
    "- [isolcpus](https://www.linuxtopia.org/online_books/linux_kernel/kernel_configuration/re46.html)\n",
    "- Blog post [series](https://vstinner.github.io/journey-to-stable-benchmark-system.html) on stabilizing your system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fff9d6-28bb-49c2-a6da-e3a1d1070a61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Techniques\n",
    "\n",
    "### Memoization\n",
    "\n",
    "This is an optimization technique that saves the results of previous invocations of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381c16e-2363-4dd3-a8b1-eb7d8c4ccfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluent Python's implementation of a time function\n",
    "import time\n",
    "\n",
    "def clock(func):\n",
    "    def clocked(*args):\n",
    "        t0 = time.time()\n",
    "        result = func(*args)\n",
    "        elapsed = time.time() - t0\n",
    "        name = func.__name__\n",
    "        arg_str = ', '.join(repr(arg) for arg in args)\n",
    "        print('[%0.8fs] %s(%s) -> %r' % (elapsed, name, arg_str, result))\n",
    "        return result\n",
    "    return clocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1ee5f-b112-468e-b1cc-4cb00f457993",
   "metadata": {},
   "outputs": [],
   "source": [
    "@clock\n",
    "def fibonacci(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n - 2) + fibonacci(n - 1)\n",
    "\n",
    "print(fibonacci(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d01206-c6d7-4db4-96c3-ade701b3e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools \n",
    "\n",
    "@functools.cache\n",
    "@clock\n",
    "def fibonacci(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n - 2) + fibonacci(n - 1)\n",
    "\n",
    "print(fibonacci(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d37b26-e38a-4287-a496-d15dcd4ecc55",
   "metadata": {},
   "source": [
    "All the arguments taken by the decorated function must be hashable, because the underlying lru_cache uses a dict to store the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c95b1d-c46e-4b50-b6c2-3240f0002c9c",
   "metadata": {},
   "source": [
    "`@cache` won't be available to you if your Python < 3.8, but you can still use `@lru_cache`.\n",
    "\n",
    "`@lru_cache` contains two arguments, `maxsize` which receives an integer containing the maximum number of entries to be stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da22578e-463f-4cdd-abb8-14f002137fc7",
   "metadata": {},
   "source": [
    "## Saving memory using slots\n",
    "\n",
    "`__slots__` is a different way of storage model for instance attributes. It's stored in a hidden array that uses less memory than a `dict`.\n",
    "\n",
    "Here we're going to take a look into how to use it and some unexpected behaviors it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235a1c7-8634-431b-90cc-042f39ebb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pixel:\n",
    "    __slots__ = ('x', 'y')\n",
    "\n",
    "p = Pixel()\n",
    "p.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d3dc3-ed83-485d-afe2-13a9f4bea25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.x = 10\n",
    "p.y = 12\n",
    "p.color = 'red'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4d61f-dfbc-4976-8326-8460c0b66fd1",
   "metadata": {},
   "source": [
    "You need to declare all the attributes that are going to be used when the class is created.\n",
    "\n",
    "ðŸ‘¥ How can we fix this code?\n",
    "\n",
    "Good, all this behavior was within the expected. Now let's take a look on what's weird about `__slots__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e21bd-4b1b-4401-9ae3-12a46efd466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecializedPixel(Pixel):\n",
    "    pass\n",
    "\n",
    "sp = SpecializedPixel()\n",
    "sp.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8943646-b000-4adc-a960-ced17f2f95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.x = 10\n",
    "sp.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3a293-e2d0-450c-9429-8d86c344f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.color = 'white'\n",
    "sp.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6be3e-8c06-493a-9a3b-ade2c446473a",
   "metadata": {},
   "source": [
    "ðŸ‘¥ What are the implications of having a `__dict__` here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c887ad35-923f-4009-9d87-4f49e08cda55",
   "metadata": {},
   "source": [
    "According to Fluent Python's profiling a list containing a custom array implementation of 10M instances using `__dict__` and `__slots__` offer very different results:\n",
    "\n",
    "```bash\n",
    "$ time python3 mem_test.py vector2d_v3\n",
    "Selected Vector2d type: vector2d_v3.Vector2d\n",
    "Creating 10,000,000 Vector2d instances\n",
    "Initial RAM usage:      6,983,680\n",
    "  Final RAM usage:  1,666,535,424\n",
    "real 0m11.990s\n",
    "user 0m10.861s\n",
    "sys 0m0.978s\n",
    "```\n",
    "\n",
    "```bash\n",
    "$ time python3 mem_test.py vector2d_v3_slots\n",
    "Selected Vector2d type: vector2d_v3_slots.Vector2d\n",
    "Creating 10,000,000 Vector2d instances\n",
    "Initial RAM usage:      6,995,968\n",
    "  Final RAM usage:    577,839,104\n",
    "real 0m8.381s\n",
    "user 0m8.006s\n",
    "sys 0m0.352s\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

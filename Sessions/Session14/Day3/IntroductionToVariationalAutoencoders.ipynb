{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VMBoehm/ML_Lectures/blob/main/IntroductionToVariationalAutoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvu91ZyEFtBQ"
      },
      "source": [
        "#**Introduction to Variational AutoEncoders (VAEs) and applications to physical data** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vg7JmIrF8PD"
      },
      "source": [
        "by Vanessa Boehm (UC Berkeley and LBNL)   \n",
        "Feb 27 2022\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this notebook we will be implementing our first Variational Autoencoder. VAEs are a useful tool for the analysis of physical data because of their probabilistic layout.   \n",
        "\n",
        "We will start from a (non-probalistic) autoencoder and convert it into its variational counterpart.\n",
        "\n",
        "## Autoencoder\n",
        "\n",
        "Recall that an Auto-Encoder consists of two networks: \n",
        "\n",
        "1.   An encoder network that takes the data, $x$, and maps it to a lower-dimensional latent space. We will call this network $f$ and its network parameters $\\phi$.\n",
        "2.   A decoder network that takes the encoded data, $z$, and maps it back to the data space. We will call the result of the reconstruction $x'$, the decoder network $g$ (for generator) and its network parameters $\\psi$.\n",
        "\n",
        "$$ x' = g_\\psi(f_\\phi(x)) \\tag{1}$$\n",
        "\n",
        "An Auto-Encoder is trained to minimize the reconstruction error between the input $x$ and the reconstruction $x'$.\n",
        "\n",
        "$$ \\mathcal{L}_{AE}(\\phi,\\psi) = ||x-g_\\psi(f_\\phi(x))||^2_2 \\tag{2}$$\n",
        "\n",
        "---\n",
        "\n",
        "## Probabilistic Interpretation (lecture recap)\n",
        "\n",
        "**In a Variational Auto-Encoder we interpret the reconstruction task  probabilistically:**\n",
        "\n",
        "Compressing the data results in a loss of information about the original data. \n",
        "If we only have access to the compressed data, we have no chance of knowing what the original data looked like *exactly*. Instead, we obtain a probability distribution over possible inputs.\n",
        "\n",
        "This motivates a probabilistic formulation of the problem: \n",
        "Let's assume that the data follows some probabiliy distribution $p(x)$ (each data point is a drawn from this distribution)\n",
        "\n",
        "$$ p(x) = \\int \\mathrm{d}z\\, p(x|z) p(z). \\tag{3}$$\n",
        "\n",
        "Here, we have introduced two probability distributions on the right hand side, the liklelihood, $p(x|z)$, and the prior, $p(z)$.\n",
        "\n",
        "The likelihood arises because of the information loss in the compression.\n",
        "\n",
        "$$ x = g_\\psi(f_\\phi(x)) + \\epsilon = g_\\psi(z) + \\epsilon \\tag{4}$$ \n",
        "\n",
        "Ideally, $\\epsilon$, the part of the data that is lost in the compression, is just noise and unimportant for our final data analysis. The form of the likelihood is equal to the distribution of this noise. For example, if the noise is Gaussian (which is often the case for physical data) with covariance $\\Sigma_\\epsilon$, the likelihood is a Gaussian distribution:\n",
        "\n",
        "$$ p_{\\psi}(x|z) = \\mathcal{G}(g_\\psi(z),\\Sigma_\\epsilon) \\tag{5}$$ \n",
        "\n",
        "**Optional Question 1**   \n",
        "Starting from $p(x|z) = \\int \\mathrm{d}\\epsilon\\, p(x,\\epsilon|z)$ can you show that the likelihood follows the same distribution as $\\epsilon$?\n",
        "\n",
        "\n",
        "The prior, $p(z)$, is the average distribution of the encoded data.\n",
        "\n",
        "$$ p(z) = \\int \\mathcal{d}x\\, p(z|x) p(x) \\tag{6}$$\n",
        "\n",
        "In a VAE, we want the prior distribution to have closed form and to be easy to sample from (for artificial data generation). We have the freedom to choose the prior distribution as a constraint. The network training will ensure it is obeyed. A common choice is a normal distribution\n",
        "\n",
        "$$ p(z) = \\mathcal{N}(0,1) \\tag{7} $$\n",
        "\n",
        "---\n",
        "\n",
        "### Variational Autoencoder & Evidence Lower BOund (ELBO)\n",
        "\n",
        "To train the Variational Auto-Encoder we maximize the average log probability, $\\log p(x)$, or, as we will see now, a lower bound to this quantity.\n",
        "\n",
        "Equation (3) involves solving a fairly high dimensional integral, which is a computationally expensive and sometimes infeasible operation. This integral has to be solved not only once, but in each training step. Variational Autoencoders  solve this integral approximately by using a variational ansatz for the posterior distribution, the approximate posterior $q_\\phi(z|x)$. This distribution approximates the true posterior p(z|x) and is parameterized by the encoder parameters $\\phi$. \n",
        "\n",
        "The classic choice for the variational posterior is a multivariate Gaussian in the mean field approxiation (mean field meaning no off-diagonal terms in the covariance)\n",
        "\n",
        "$$ q_\\phi(z|x) = \\mathcal{G}(\\mu,\\sigma_i) \\tag{7} $$\n",
        "\n",
        "where the mean, $\\mu$, and variance, $\\sigma$, are determined by the encoder network. \n",
        "\n",
        "$$(\\mu, \\sigma) = f_\\phi(x) \\tag{8} $$\n",
        "\n",
        "As we saw in the lecture, the variational ansatz allows us to formulate a lower bound to $\\log p(x)$, the Evidence Lower BOund.\n",
        "\n",
        "$$ \\log p(x) >= \\int \\mathrm{d}z\\, q_\\phi(z|x) \\log{p_\\psi(x|z)} - \\int \\mathrm{d}z\\, q_\\phi(z|x) \\log{\\frac{q_\\phi(z|x)}{p(z)}} = ELBO \\tag{8}$$\n",
        "\n",
        "$$ \\mathcal{L}_{VAE}(\\phi,\\psi) = -ELBO \\tag{9}$$\n",
        "\n",
        "The ELBO consists of two terms. The first term measures the expectation value of the likelihood over the posterior. Maximizing this term encourages high quality reconstructions (similar to the autoencoder). The second term is the KL-Divergence (a distance measure) between the variational posterior and the prior. This term acts as a regularizer. It encourages posterior distributions which are similar to the prior.\n",
        "\n",
        "In VAE training the first term is evaluated stochastically, meaning that the expectation value is evaluated approximately by averaging over a number of samples from $q_\\phi(z|x)$. The second term can be either evaluated analytically (the KL divergence between to Gaussian distributions can be calculated) or stochastically. \n",
        "\n",
        "---\n",
        "\n",
        "### Reparametrization Trick\n",
        "\n",
        "Minimizing Eq. (9) requires taking gradients with respect to $\\phi$ and $\\psi$. But how do we take the gradient through an expectation value?  \n",
        "\n",
        "We use what is called the reparametrization trick. Instead of sampling from the posterior $q_\\phi(z|x)$ we sample from the parameter-independent normal distribution\n",
        "\n",
        "$$ \\zeta ∼ \\mathcal{N}(0,1) \\tag{10}$$\n",
        "\n",
        "and use the identity $z=\\zeta*\\sigma_\\phi+\\mu_\\phi$, an operation which is trivially differentiably, to obtain our samples.\n",
        "\n",
        "Pytorch will perform the reparametrization trick for us under the hood, if we use *distribution.rsample()* - so we don't have to code it explicitly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **End of recap. Begin of coding exercise!**\n",
        "In this first part, all you need to do is download the dataset and read through the code. You learned about Autoencoders yesterday, so all you need to do is go through the code below and make sure you understand it. We will start modifying it in the next section."
      ],
      "metadata": {
        "id": "d524M2J-MB6X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNZMyGZEuMJY"
      },
      "source": [
        "Let' start by importing a few packages, that we will need later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iquM2NAFde_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLVu9iy4BFu"
      },
      "source": [
        "### Our dataset\n",
        "\n",
        "In this coding exercise we will be working with a galaxy spectra sample from the SDSS-BOSS DR 16 release. The spectra have been de-redshifted to the restframe and their magnitude has been standardized to a distance correspondingg to $z_\\lambda=0.1$. They have further been downsampled to 1000 pixels, denoised and inpainted where masks were present.\n",
        "\n",
        "(I can tell you more about the data cuts and preprocessing if you are interested, but it is not relevant for this task.)\n",
        "\n",
        "Despite being relatively high-dimensional ($d=1000$), galaxy specrtra actually reside on a lower dimensional manifold. An indication for this is that we can compress them to much smaller dimensionality without sacrificing much reconstruction quality. \n",
        "\n",
        "This property makes them a very suitable data type for VAEs. \n",
        "\n",
        "(The same applies to image data, but images datasets are computationally more expensive to train on and they need more complicated nework architectures - things that we don't want to worry about in this exercise.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK4VXXUUq4vi"
      },
      "source": [
        "STEP 1: Download the training and test datasets \n",
        "\n",
        "1.   [training set](https://drive.google.com/file/d/1oGe1zsgyCEBY1N_t-GkxxoSgVnJyTms2/view?usp=sharing)\n",
        "2.   [test set](https://drive.google.com/file/d/1wXtOpUKGj2gMff2KbBfY4x8HnzxguyXJ/view?usp=sharing)\n",
        "\n",
        "and place them in your Google Drive. (If you want to avoid having to modify the file paths in the code below, you need to create a folder called 'ML_lecture_data' and place the files in there.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEFkPFXwtJQ5"
      },
      "source": [
        "Next, we link Google Drive to this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RauugG-yVWQu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qlleg5Ptwry"
      },
      "source": [
        "Use this line to confirm the location of your files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYJWjZQ2VqNH"
      },
      "outputs": [],
      "source": [
        "! ls drive/MyDrive/ML_lecture_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwlmXPZpxnyo"
      },
      "source": [
        "Let's set some immutable variables:\n",
        "The dimensionality of the input data and the dimensionality of the latent (encoded) space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMnt57iDXqIJ"
      },
      "outputs": [],
      "source": [
        "INPUT_SIZE      = 1000\n",
        "LATENT_SIZE     = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU4ULbV5x0wd"
      },
      "source": [
        "Next we create pytorch datasets from the training and test data (note that you need to change the root_dir, if you placed the data in a different folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhaWK_EWF7R_"
      },
      "outputs": [],
      "source": [
        "class SDSS_DR16(Dataset):\n",
        "    \"\"\"De-redshifted and downsampled spectra from SDSS-BOSS DR16\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir='drive/MyDrive/ML_lecture_data/', transform=True, train=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory of data file\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "\n",
        "        if train:\n",
        "            self.data = np.load(open(os.path.join(root_dir,'DR16_denoised_inpainted_train.npy'),'rb'),allow_pickle=True)\n",
        "        else:\n",
        "            self.data = np.load(open(os.path.join(root_dir,'DR16_denoised_inpainted_test.npy'),'rb'),allow_pickle=True)\n",
        "\n",
        "        self.data = torch.as_tensor(self.data)\n",
        "        self.mean = torch.mean(self.data)\n",
        "        self.std  = torch.std(self.data)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        sample = (self.data[idx]-self.mean)/self.std\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "#initialize datasets\n",
        "training_data = SDSS_DR16(train=True)\n",
        "test_data     = SDSS_DR16(train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYciZ7mJ3CvT"
      },
      "source": [
        "##**Autoencoder**\n",
        "This exercise starts with an Autoencoder, which is already implemented and working. The next cells walk you through the code. Your task (further below) will be to take that code and modify it into a Variational Autoencoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXtpdS3OyG5Y"
      },
      "source": [
        "First, we define our encoder and decoder networks. We use a very simple MLP, with two linear layers and one non-linear activation function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1udif2UYQOw"
      },
      "outputs": [],
      "source": [
        "# we inherit from pytorch Module class; https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, seed=853):\n",
        "        \"\"\"\n",
        "        seed: int, random seed for reproducibility\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        # here we are initializing the linear layers. This registeres the layer parameters (W,b) as parameters of the Module\n",
        "        self.fc1 = nn.Linear(INPUT_SIZE,50)\n",
        "        self.fc2 = nn.Linear(50,LATENT_SIZE)\n",
        "\n",
        "    # this defines a forward pass of the network (=\"applying\" the network to some input data)\n",
        "    def forward(self, x):\n",
        "        x      = torch.nn.LeakyReLU()(self.fc1(x))\n",
        "        z      = self.fc2(x)\n",
        "        return z\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, seed=620):\n",
        "        \"\"\"\n",
        "        seed: int, random seed for reproducibility\n",
        "        \"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(LATENT_SIZE,50)\n",
        "        self.fc2 = nn.Linear(50,INPUT_SIZE)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = torch.nn.LeakyReLU()(self.fc1(z))\n",
        "        x = self.fc2(z)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt_mADqDy3cD"
      },
      "source": [
        "Having defined the encoder and decoder network, we can move on to define the Autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGzcsBeeau1t"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # here we are creating instances of the Encoder and Decoder class\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x = self.decoder(z)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2yyNsVUcNR-"
      },
      "outputs": [],
      "source": [
        "# This creates an instance of the Autoencoder class\n",
        "AE = Autoencoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEuNOP4N0X0O"
      },
      "source": [
        "The next step is to train the Autoencoder. This is what a generic training loop looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH1elQeObtEE"
      },
      "outputs": [],
      "source": [
        "# the training loop takes a function that loads the data batch by batch, a model to train, a loss function to train the model on and an optimizer\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    losses = []\n",
        "    # iterate over the dataset\n",
        "    for batch, X in enumerate(dataloader):\n",
        "        # Compute prediction of the model (in case of the AE the prediction is the reconstructed data)\n",
        "        pred = model(X)\n",
        "        # Compute the loss function (in case of the AE this is the L2 distance to the input data)\n",
        "        loss = loss_fn(pred,X)\n",
        "\n",
        "        # Backpropagation; this is where we take the gradient and update the network parameters\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # here we keep track of the loss\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            losses.append(loss)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    \n",
        "    return losses\n",
        "\n",
        "\n",
        "# the test loop is similar to the training loop, only that we don't take any gradients/don't update the network parameters, but only evaluate\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss =  0\n",
        "    with torch.no_grad():\n",
        "        for X in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, X).item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    print(f\" Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KqrUXUY3KW-"
      },
      "source": [
        "In the next cell we set the training parameters, define the loss function and create DataLoaders. Pytorch DataLoaders manage the data loading for us (break the dataset into batches, keep track of epochs, reshuffle the data after each epoch) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9brCNsq0m8N"
      },
      "outputs": [],
      "source": [
        "BATCHSIZE       = 128\n",
        "BATCHSIZE_TEST  = 256\n",
        "LEARNING_RATE   = 1e-3\n",
        "\n",
        "# MeanSquaredError (L2) Loss\n",
        "loss_fn         = nn.MSELoss()\n",
        "# Adam Optimizer\n",
        "optimizer       = torch.optim.Adam(AE.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Dataloaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=BATCHSIZE, shuffle=True)\n",
        "test_dataloader  = DataLoader(test_data, batch_size=BATCHSIZE_TEST, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrVfwZ6x3ytf"
      },
      "source": [
        "It's finally time for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO2GEEoEffAk"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 30\n",
        "SEED   = 555  \n",
        "\n",
        "train_loss = []\n",
        "test_loss  = []\n",
        "for t in range(EPOCHS):\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss.append(train_loop(train_dataloader, AE, loss_fn, optimizer))\n",
        "    test_loss.append(test_loop(test_dataloader, AE, loss_fn))\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da7lOSzE4J6f"
      },
      "source": [
        "Let's see how the model is doing. Let's look at \n",
        "\n",
        "1.   Training and test loss \n",
        "2.   Final reconstruction quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24qdCadyhXVU"
      },
      "outputs": [],
      "source": [
        "# losses\n",
        "length = len(np.asarray(train_loss).flatten())\n",
        "plt.figure()\n",
        "plt.plot(np.linspace(0,length*100,length), np.asarray(train_loss).flatten(),label='training set')\n",
        "plt.plot(np.linspace(100,(length)*100,len(test_loss)),test_loss,label='test set')\n",
        "plt.xlabel('training step')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "### zoom in \n",
        "length = len(np.asarray(train_loss).flatten())\n",
        "plt.figure()\n",
        "plt.plot(np.linspace(0,length*100,length), np.asarray(train_loss).flatten(),label='training set')\n",
        "plt.plot(np.linspace(100,(length)*100,len(test_loss)),test_loss,label='test set')\n",
        "plt.xlabel('training step')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.ylim(0,0.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZA9Vz3-5Di-"
      },
      "source": [
        "You can see that the model had a really easy time learning the task and that we haven't overfitted yet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4hzPWZP5Um8"
      },
      "source": [
        "Now, let's look at a few reconstructions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVVJ6vwUASd1"
      },
      "outputs": [],
      "source": [
        "test_input = next(iter(test_dataloader))\n",
        "\n",
        "with torch.no_grad():\n",
        "  recons = AE(test_input)\n",
        "\n",
        "# This is the mapping from pixel to the de-redshifted (rest) wavelength\n",
        "wlmin, wlmax      = (3388,8318)\n",
        "fixed_num_bins    = 1000\n",
        "wl_range          = (np.log10(wlmin),np.log10(wlmax))\n",
        "wl                = np.logspace(wl_range[0],wl_range[1],fixed_num_bins)\n",
        "\n",
        "fig, ax = plt.subplots(4,4, figsize=(20,10), sharex=True)\n",
        "ax = ax.flatten()\n",
        "for ii in range(16):\n",
        "  ax[ii].plot(wl,test_input[ii], label='input')\n",
        "  ax[ii].plot(wl,recons[ii],alpha=0.7,label='reconstruction')\n",
        "  if ii in np.arange(12,16):\n",
        "    ax[ii].set_xlabel('wavelength [Ångströms]')\n",
        "  if ii in [0,4,8,12]:\n",
        "    ax[ii].set_ylabel('some standardized flux')\n",
        "  if ii==0:\n",
        "    ax[ii].legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oqkoegOKP3G"
      },
      "source": [
        "... and the average reconstruction error as a function of wavelength:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyHOlus2I3zE"
      },
      "outputs": [],
      "source": [
        "avg_loss  = 0\n",
        "with torch.no_grad():\n",
        "    for X in test_dataloader:\n",
        "        pred = AE(X)\n",
        "        avg_loss+=np.mean((pred.cpu().numpy()-X.cpu().numpy())**2,axis=0)/(len(test_data)//BATCHSIZE_TEST)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(wl,np.sqrt(avg_loss))\n",
        "plt.ylabel('average reconstruction error')\n",
        "plt.xlabel('wavelength [Ångströms]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optional: save the model weights\n",
        "#torch.save(AE.state_dict(), 'drive/MyDrive/ML_lecture_models/AE_model_weights.pth')"
      ],
      "metadata": {
        "id": "VisR7dVUTqzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few things you might have noticed and that can be useful to keep in mind:\n",
        "\n",
        "\n",
        "*   The model expects a single precision input. You can change the type of a tensor with tensor_name.type(), where tensor_name is the name of your tensor and type is the dtype. For typecasting into single precision floating points, use float(). A numpy array is typecasted with array_name.astype(type). For single precision, the type should be np.float32.\n",
        "*   Before we analyze tensors we often want to convert them to numpy arrays with tensor_name.numpy()\n",
        "*   If pytorch has been tracking operations that resulted in the current tensor value, you need to detach the tensor from the graph before you can transform it into a numpy array: tensor_name.detach(). Scalars can be detached with scalar.item()\n",
        "*   If you tensor is currently on the GPU, you can bring it onto the CPU with tensor_name.cpu()"
      ],
      "metadata": {
        "id": "ZG9cNGp7Rnda"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtndaU2ubVov"
      },
      "source": [
        "## **Variational Autoencoder**\n",
        "\n",
        "Your task today is to transform the above Autoencoder into a Variational Autoencoder. You can follow either follow my Step-by-Step instructions or do it your way (there's more than one solution). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6YJ6mtGLwS4"
      },
      "source": [
        "We start by modifying the encoder network. Tasks are marked with the keyword #TASK, hints are marked with the keyword #HINT. Question marks are used to indicate places where you need to fill in code in order to recover the solutions. You don't have to follow the structure of the solutions, there's more than one way to code a VAE. You can also replace the statements with your own code if you find your approach more intuitive! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGEjVfDFNRvl"
      },
      "source": [
        "### **STEP 1:** Modify the encoder network.\n",
        "The encoder network is used to characterize the variational distribution q(z|x). Recall that we want q(z|x) to be a Gaussian with diagonal covariance. An N-dimensional Gaussian with diagonal covariance is eqivalent to N independent 1-dimensional Gaussians (where N is the latent size). Each Gaussian is defined by two quantities, its mean and variance (or, if we take the sqrt, the standard deviation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKMNpHaeb93k"
      },
      "outputs": [],
      "source": [
        "class VAEEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, seed=853):\n",
        "        super(VAEEncoder, self).__init__()\n",
        "        #TASK: change the output size of the encoder network. How many parameters must it return to define q(z|x)?\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(INPUT_SIZE,50)\n",
        "        self.fc2 = nn.Linear(50,??)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #TASK: change the output of the encoder network. Instead of just returning z, it should return z and ...?\n",
        "        #HINT: Don't forget that the standard deviation/variance must be strictly positive!\n",
        "        #HINT: You might want to use torch.split(): https://pytorch.org/docs/stable/generated/torch.split.html\n",
        "        x      = torch.nn.LeakyReLU()(self.fc1(x))\n",
        "        x      = self.fc2(x)\n",
        "        mu,std = ??\n",
        "        std    = ??\n",
        "        return mu, std\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4X2ctPEO2tF"
      },
      "source": [
        "### **STEP 2:** Modify the decoder network.\n",
        "\n",
        "We will leave our decoder network as it is :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-_V5PYNMNSy"
      },
      "outputs": [],
      "source": [
        "class VAEDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, seed=620):\n",
        "        super(VAEDecoder, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(LATENT_SIZE,50)\n",
        "        self.fc2 = nn.Linear(50,INPUT_SIZE)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = torch.nn.LeakyReLU()(self.fc1(z))\n",
        "        x = self.fc2(z)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgn_SFibPDPj"
      },
      "source": [
        "Since we work with probability distributions in the VAE, we need to import the torch distributions package. We will only need the normal distribution for this exercise. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8pX6vYGS0nJ"
      },
      "outputs": [],
      "source": [
        "#TASK: Familiarize yourself with torch.distribution.Normal - you can find the documentation here: https://pytorch.org/docs/stable/distributions.html#normal\n",
        "#HINT: It takes a standard deviation (scale) not a variance as input\n",
        "from torch.distributions import Normal as Normal "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLmhg1d9Pkm-"
      },
      "source": [
        "### **STEP 3:** Modify the AE class into a VAE class!\n",
        "\n",
        "\n",
        "\n",
        "1.   A VAE has a few more input parameters than an AE. We need a sample size, which determines how many samples we draw from $q_\\phi(z|x)$ for evaluating the ELBO. We also need a $\\sigma_\\epsilon$ to characterize the likelihood, $p_\\psi(x|z)=\\mathcal{G}(x',\\sigma_\\epsilon)$.\n",
        "2.   The prior is fixed. We can define it in the beginning, when we initialize the VAE.\n",
        "3.   We need methods to compute the variational posterior, the likelihood, the KL-divergence and the ELBO.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IblX0IgkbcMI"
      },
      "outputs": [],
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    #TASK: add parameters mentioned in point 1. \n",
        "    def __init__(self, ??, ??):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.encoder = VAEEncoder()\n",
        "        self.decoder = VAEDecoder()\n",
        "        self.\"insert name of param1 here\" = ??\n",
        "        self.\"insert name of param2 here\" = ??\n",
        "        #TASK: Use the Normal class to define the prior (a standard normal distribution), p(z)\n",
        "        self.prior       = ??\n",
        "\n",
        "    def get_q(self,x):\n",
        "        #TASK: write a method that computes q(z,x)\n",
        "        #HINT: use the Normal class we imported above\n",
        "        mu, std = ??\n",
        "        self.q  = ??\n",
        "        return True\n",
        "\n",
        "    def sample_q(self):\n",
        "        #TASK: write a method that samples from q\n",
        "        #HINT: use rsample to apply the reparameterization trick\n",
        "        #HINT: rsample takes a list or array of shapes as input, e.g. [sample_size]\n",
        "        z_sample = ??\n",
        "        return z_sample\n",
        "\n",
        "        #TASK (Optional): write a method that allows to change how many samples are drawn from q(z|x)\n",
        "    def change_sample_size(self,??):\n",
        "        ?? = ??\n",
        "        return True\n",
        "\n",
        "    def get_avg_log_likelihood(self,recons,x):\n",
        "        #TASK: Write a method that returns the first term in the ELBO (this method should define the likelihood and evaluate the average log likelihood of the reconstruction)\n",
        "        #HINT: Pay attention to shapes. The function should return an average log likelihood (a single number) for every data point in the batch.\n",
        "        #HINT: The output shape of Normal(mu, sigma).log_prob() is a little unintuitive. If mu or sigma are N-dimensional, it returns N results (applies N independent Gaussians). \n",
        "        #HINT: You need to average over samples from q to obtain the final result.\n",
        "        ll    = ??\n",
        "        log_p = ??\n",
        "        log_p = ??\n",
        "        return ??\n",
        "\n",
        "    def stochastic_kl_divergence(self,z_sample):\n",
        "        #TASK: Write a method that computes the kl-divergence between q(z|x) and p(z) \n",
        "        #HINT: Pay attention to shape\n",
        "        return ??\n",
        "\n",
        "    def forward(self, x):\n",
        "        #TASK: a forward pass should return the two terms in the ELBO\n",
        "        #HINT: use all the methods we defined above\n",
        "        ??\n",
        "        samples = ??\n",
        "        recons  = ??\n",
        "        log_likelihood = ??\n",
        "        kl      = ??\n",
        "        return log_likelihood, kl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox7VgW-R6W6P"
      },
      "source": [
        "### **STEP 4**: Prepare for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DYaUij-WkK3"
      },
      "outputs": [],
      "source": [
        "#TASK: create an instance of the Variational Autoencoder with sample_size=4 and sigma=1\n",
        "VAE = ??\n",
        "\n",
        "optimizer = torch.optim.Adam(VAE.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "\n",
        "#from torch.optim.lr_scheduler import StepLR\n",
        "#scheduler = StepLR(optimizer, step_size=10, gamma=0.75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw8MYTJWW4N8"
      },
      "outputs": [],
      "source": [
        "#TASK: define the new loss function\n",
        "def negative_ELBO(avg_log_likelihood,kl):\n",
        "\n",
        "    negative_ELBO = ??\n",
        "\n",
        "    return negative_ELBO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yjd0yE4WrKc"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    losses = []\n",
        "    for batch, X in enumerate(dataloader):\n",
        "        #TASK: compute the loss from the output of the VAE foward pass  \n",
        "        log_likelihood, kl = ??\n",
        "        loss = ??\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            losses.append(loss)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "    #scheduler.step()\n",
        "    return losses\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, nllh, kl_ = 0, 0, 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X in dataloader:\n",
        "            #TASK: in the test loop we want to keep track not only of the ELBO, but also of the two terms that contribute to the ELBO (kl diveregence and loglikelihood)\n",
        "            log_likelihood, kl = ??\n",
        "            test_loss += ??.item()\n",
        "            nllh += ??\n",
        "            kl_ += ??\n",
        "\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    kl_ /= num_batches\n",
        "    nllh /= num_batches\n",
        "\n",
        "    print(f\" Avg test loss      : {test_loss:>8f}\")\n",
        "    print(f\" Avg KL             : {kl_:>8f}\")\n",
        "    print(f\" Avg negative log likelihood : {nllh:>8f} \\n\")\n",
        "\n",
        "    return test_loss, kl_, nllh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZMlhzGoYJvX"
      },
      "source": [
        "Let's train!    \n",
        "**Note:** Training a VAE can be unstable. If things get weird, try changing the random seed or hyperparameters, such as the number of epochs, batchsize, learning rate, sample size, likelihood noise level...\n",
        "\n",
        "**HINT:** To get good artificial data samples, you need to have a KL divergence in the single digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Udr9UnLXmJf"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 8\n",
        "SEED   = 1234\n",
        "\n",
        "train_loss = []\n",
        "test_loss  = []\n",
        "for t in range(EPOCHS):\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss.append(train_loop(train_dataloader, VAE, negative_ELBO, optimizer))\n",
        "    test_loss.append(test_loop(test_dataloader, VAE, negative_ELBO))\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXZtkOVVFuNK"
      },
      "outputs": [],
      "source": [
        "test_loss = np.asarray(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7syew_eAXpfj"
      },
      "outputs": [],
      "source": [
        "#TASK: plot the training loss, test loss, and the contributions to the loss from each of the two terms \n",
        "length = len(np.asarray(train_loss).flatten())\n",
        "plt.figure()\n",
        "??\n",
        "plt.xlabel('training step')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0tcAyjRaZ8W"
      },
      "outputs": [],
      "source": [
        "# TASK: Inspect how the contribution of the kl divergence and log likelihood to the loss change as you change the noise in the likelihood. Some suggested values: sigma=[0.5,1,2]\n",
        "# TASK: what happens when you change the number of samples?\n",
        "# What do you observe? Can you interpret it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6RbwE2BXxrU"
      },
      "source": [
        "### **STEP 5:** Inspect the model performance\n",
        "\n",
        "Similar to the AE, we will look at the average reconstruction quality. But in addition, we also want to know how well the kl term was minimized. We will therefore look at three things\n",
        "\n",
        "1.   Reconstruction quality\n",
        "2.   Scatter plots of posterior samples and prior samples. Recall that $p(z)=\\int \\mathcal{d}x\\, p(x,z) \\approx \\frac{1}{N_{samples}} \\sum_{x\\sim p(x)} p(z|x)$.\n",
        "3.   Quality of artificial data generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvdilGwgXmKU"
      },
      "outputs": [],
      "source": [
        " #TASK: plot the average reconstruction error of the model as a function of wavelength (similar to above). How does it compare to the Autoencoder?\n",
        " #HINT: Use the mean of $q(z|x)$ as the latent point for data x\n",
        "avg_loss  = 0\n",
        "VAE.eval()\n",
        "with torch.no_grad():\n",
        "    for X in test_dataloader:\n",
        "        pred = ??\n",
        "        avg_loss+=??\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(wl,np.sqrt(avg_loss))\n",
        "plt.ylabel('average reconstruction error')\n",
        "plt.xlabel('wavelength [Ångströms]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zbCDqW93Vwp"
      },
      "outputs": [],
      "source": [
        "#TASK: make a corner plot of posterior samples. Does the average posterior match the prior?\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "VAE.eval()\n",
        "with torch.no_grad():\n",
        "    for ii, X in enumerate(test_dataloader):\n",
        "        VAE.get_q(X)\n",
        "        prior_sample = ??\n",
        "        sample       = ??\n",
        "        if ii==0:\n",
        "          samples       = sample\n",
        "          prior_samples = prior_sample\n",
        "        else:\n",
        "          samples       = np.vstack([samples, sample])\n",
        "          prior_samples = np.vstack([prior_samples, prior_sample])\n",
        "\n",
        "samples       = np.reshape(samples,[-1, LATENT_SIZE])\n",
        "prior_samples = np.reshape(prior_samples,[-1, LATENT_SIZE])\n",
        "\n",
        "print(samples.shape)\n",
        "print(prior_samples.shape)\n",
        "\n",
        "data1    = pd.DataFrame()\n",
        "data2    = pd.DataFrame()\n",
        "\n",
        "for ii in range(LATENT_SIZE):\n",
        "  data1['dim_%d'%ii] = samples[:,ii]\n",
        "data1['source'] = 'posterior'\n",
        "\n",
        "for ii in range(LATENT_SIZE):\n",
        "  data2['dim_%d'%ii] = prior_samples[:,ii]\n",
        "data2['source'] = 'prior'\n",
        "\n",
        "data = pd.concat([data1,data2]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "#HINT: to get a density estimate you can set kind='kde', but you'll probably have to reduce the number of samples, KDE optimization scales pretty badly with number of samples\n",
        "sns.pairplot(data,corner=True,kind='scatter', hue='source', plot_kws={'s':4})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62rkkkwbewKi"
      },
      "outputs": [],
      "source": [
        "#TASK: Generate artificial data: sample from the prior and foward model the sample thorugh the decoder. Do the samples look realistic? Why?/Why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhYlgfZLm_iI"
      },
      "outputs": [],
      "source": [
        "VAE.eval()\n",
        "with torch.no_grad():\n",
        "  samples      = ??\n",
        "  data_samples = ??\n",
        "\n",
        "# This is the mapping from pixel to the de-redshifted (rest) wavelength\n",
        "wlmin, wlmax      = (3388,8318)\n",
        "fixed_num_bins    = 1000\n",
        "wl_range          = (np.log10(wlmin),np.log10(wlmax))\n",
        "wl                = np.logspace(wl_range[0],wl_range[1],fixed_num_bins)\n",
        "\n",
        "fig, ax = plt.subplots(4,4, figsize=(20,10), sharex=True)\n",
        "ax = ax.flatten()\n",
        "for ii in range(16):\n",
        "  ax[ii].plot(wl,data_samples[ii], label='artificial data')\n",
        "  if ii in np.arange(12,16):\n",
        "    ax[ii].set_xlabel('wavelength [Ångströms]')\n",
        "  if ii in [0,4,8,12]:\n",
        "    ax[ii].set_ylabel('some standardized flux')\n",
        "  if ii==0:\n",
        "    ax[ii].legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv9N4V6gpJCi"
      },
      "outputs": [],
      "source": [
        "#Optional: Save model weights\n",
        "\n",
        "# torch.save(VAE.state_dict(), 'drive/MyDrive/ML_lecture_models/VAE_model_weights.pth')\n",
        "# torch.save(VAE.encoder.state_dict(), 'drive/MyDrive/ML_lecture_models/Encoder_model_weights.pth')\n",
        "# torch.save(VAE.decoder.state_dict(), 'drive/MyDrive/ML_lecture_models/Decoder_model_weights.pth')\n",
        "# VAE.load_state_dict(torch.load('drive/MyDrive/ML_lecture_models/VAE_model_weights.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vGUa83jsbOMx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "IntroductionToVariationalAutoencoders.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZwDXE34cYQXJl/DRF8gZs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
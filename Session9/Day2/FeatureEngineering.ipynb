{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as GridSpec\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Features as a Representation of Time Series for Classification\n",
    "\n",
    "**version 0.1**\n",
    "\n",
    "***\n",
    "By AA Miller (Northwestern CIERA/Adler Planetarium)\n",
    "\n",
    "10 June 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This lecture is about machine learning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But honestly, this lecture isn't really about machine learning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This lecture *is* about the classification of variable sources in astronomical survey data. There are many different ways to approach such a classification problem, and today we will use a machine leaning approach to accomplish this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As a(n incredibly) brief reminder, machine learning algorithms use a training set with known labels$^1$ to develop a mapping between the data and the labels. You can, and should, think of this mapping as a black box. The mapping can occur between the raw data and the labels (e.g., neural net classification of images) or between representative features$^2$ and the labels.\n",
    "\n",
    "$^1$ Labels are the parameters of interest to be estimated (a variable star classification in this case).\n",
    "\n",
    "$^2$Features = measured properties of the sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once the mapping between the data and the labels has been learned from the training set, new classifications can be obtained by applying the machine learning model to sources where the labels are unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Break Out Problem 1**\n",
    "\n",
    "Why would it be useful to measure features from astronomical light curves in order to classify them in an automated fashion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Solution to Break Out 1**\n",
    "\n",
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The peculiarities of astronomical light curves (observational gaps, heteroskedastic uncertainties, etc) makes it difficult to compare any 2 random sources. For example, the cadence of observations in one portion of the sky will ultimately be very different from any other point on the sky separated by an appreciable distance ($\\sim 100^\\circ$ for LSST). \n",
    "\n",
    "The use of features allows us to place all sources on the same basis. In this way it then becomes possible to make 1 to 1 comparisons between sources with different observing sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 1) The ML Training Set\n",
    "\n",
    "Here we are going to define some helper functions that you may find helpful in your efforts to build this variable star classification model.\n",
    "\n",
    "These functions include `lc_plot`, which will produce a nice plot of the light curve showing the full duration of the observations as well as a phase folded light curve.\n",
    "\n",
    "And `read_lc`, which can quickly read the data format provided for the light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def lc_plot(t, m, m_unc, period=0.0):\n",
    "    if period == 0.0:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.errorbar(t, m, m_unc, \n",
    "                    fmt='o', color='MediumAquaMarine',\n",
    "                    mec=\"0.2\",mew=0.5)\n",
    "        ax.set_xlabel('HJD (d)')\n",
    "        ax.set_ylabel(r'$V_\\mathrm{ASAS}\\;(\\mathrm{mag})$')\n",
    "        fig.gca().invert_yaxis()\n",
    "    elif period != 0.0:\n",
    "        fig = plt.figure()\n",
    "        gs = GridSpec.GridSpec(5, 1)\n",
    "        ax_full = plt.subplot(gs[:2, :])\n",
    "        ax_full.errorbar(t, m, m_unc, \n",
    "                         fmt='o', color='MediumAquaMarine',\n",
    "                         mec=\"0.2\",mew=0.5)\n",
    "        ax_full.set_xlabel('HJD (d)')\n",
    "        ax_full.set_ylabel(r'$V_\\mathrm{ASAS}\\;(\\mathrm{mag})$')\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "        ax_phase = plt.subplot(gs[2:, :])\n",
    "        for repeat in [-1, 0, 1]:\n",
    "            ax_phase.errorbar(t/period % 1 + repeat, m, m_unc, \n",
    "                             fmt='o', color='MediumAquaMarine',\n",
    "                             mec=\"0.2\",mew=0.5)\n",
    "        ax_phase.axvline(x=0, ls='--', color='0.8', lw=1, zorder=3)\n",
    "        ax_phase.axvline(x=1, ls='--', color='0.8', lw=1, zorder=3)\n",
    "        ax_phase.set_xlim(-0.2, 1.2)\n",
    "        ax_phase.set_xlabel('Phase')\n",
    "        ax_phase.set_ylabel(r'$V_\\mathrm{ASAS}\\;(\\mathrm{mag})$')\n",
    "        plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def read_lc(filename):\n",
    "    hjd, mag, mag_unc = np.loadtxt(filename, unpack=True)\n",
    "    return hjd, mag, mag_unc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If you did not already have the training set, download and unpack the [tarball](https://northwestern.box.com/s/o6knkdzvabk9tc3u0diizpqrhhae70xq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will be working with data from the [ASAS survey](http://www.astrouw.edu.pl/asas/), and I have already curated a training set that only includes stars in 1 of 7 classes: Mira variables, RR Lyrae stars, detatched eclipsing binaries, semi-detatched eclipsing binaries, W UMa binaries, Cepheids, and R Cor Bor stars. \n",
    "\n",
    "[If you don't know what any of these things are, don't worry, we have examples below.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 1a**\n",
    "\n",
    "Plot an example Mira light curve.\n",
    "\n",
    "*Hint* - just execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Mira example\n",
    "t, m, m_unc = read_lc(\"./training_lcs/181637+0341.6\")\n",
    "lc_plot(t, m, m_unc, period=150.461188)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 1b**\n",
    "\n",
    "Plot an example RR Lyrae light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# RRL example\n",
    "t, m, m_unc = read_lc(\"./training_lcs/011815-3912.8\")\n",
    "lc_plot(t, m, m_unc, period=0.510918)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 1c**\n",
    "\n",
    "Plot an example detatched eclipsing binary (EB) light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# dEB example\n",
    "t, m, m_unc = read_lc(\"./training_lcs/153835-6727.8\")\n",
    "lc_plot(t, m, m_unc, period=2*1.107174)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 1d**\n",
    "\n",
    "Plot an example semi-detatched EB light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# aEB example\n",
    "t, m, m_unc = read_lc(\"./training_lcs/141748-5311.2\")\n",
    "lc_plot(t, m, m_unc, period=1.514158)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 1e**\n",
    "\n",
    "Plot an example W UMa EB light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# WU example\n",
    "t, m, m_unc = read_lc(\"./training_lcs/193546-1136.3\")\n",
    "lc_plot(t, m, m_unc, period=0.424015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 1f**\n",
    "\n",
    "Plot an example Cepheid light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Cepheid example\n",
    "t, m, m_unc = read_lc(\"./training_lcs/065640+0011.4\")\n",
    "lc_plot(t, m, m_unc, period=4.022837)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 1g**\n",
    "\n",
    "Plot an example R Cor Bor star light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# R Cor Bor example\n",
    "t, m, m_unc = read_lc(\"./training_lcs/163242-5315.6\")\n",
    "lc_plot(t, m, m_unc, period=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 2) Machine Learning Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To classify newly observed light curves we need a machine learning model.\n",
    "\n",
    "Previously I said this is not a machine learning problem, and that is because we will all use the same pre-specified model. I have provided a file `training_sources.csv` which includes the name of the sources, along with some features, and their classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 2a**\n",
    "\n",
    "Read in the training set file, and create a feature vector `X` and label array `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"training_sources.csv\")\n",
    "\n",
    "X_train = np.array(train_df[[\"mean\", \"nobs\", \"duration\"]])\n",
    "y_train = np.array(train_df[\"Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The provided training set comes with 3 features: i) the mean magnitude of the observations, ii) the total number of observations obtained, and iii) the duration of the observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 2b**\n",
    "\n",
    "Using the helper function provided below, calculate the 10-fold cross-validation accuracy of a random forest machine learning model using the 3 features provided above.\n",
    "\n",
    "*Note* - do not adjust any part of `calc_cv_score` throughout this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cv_score(X, y):\n",
    "    rf_clf = RandomForestClassifier(n_estimators=150, min_samples_leaf=1)\n",
    "    \n",
    "    cv_score = cross_val_score(rf_clf, X, y, cv=10, n_jobs=-1)\n",
    "    \n",
    "    print(\"These features have CV accuracy = {:.4f} +/- {:.4f}\".format(np.mean(cv_score), np.std(cv_score, ddof=1)))\n",
    "\n",
    "calc_cv_score( # complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 3) Feature Engineering\n",
    "\n",
    "It should now be clear why this is not a machine learning problem. We have, in this case, provided all the machine learning code that you will need.\n",
    "\n",
    "Instead, this is a feature engineering problem. Feature engineering requires the utilization of domain knowledge to create new features for a data set to improve the performance of machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Add new features - if necessary\n",
    "  - Utilize domain knowledge to create/compute new features\n",
    "  - Combine features or represent them in an alternative fashion\n",
    "\n",
    "Remove noisy/uniformative features - if necessary\n",
    "  - Determine feature importance (RF)\n",
    "  - Forward/backward selection to iteratively remove features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Below I have provided a partial function `calc_feature` which you can alter to calculate new features for the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def calc_feature(df, train=True):\n",
    "    \n",
    "    if train==True:\n",
    "        lc_dir = \"./training_lcs/\"\n",
    "    else:\n",
    "        lc_dir = \"./test_lcs/\"\n",
    "    \n",
    "    feature = np.empty(len(df))\n",
    "    for source_num, asas_id in enumerate(df[\"ASAS_ID\"]):\n",
    "        t, m, mu = read_lc(lc_dir+asas_id)\n",
    "        # feature calculations\n",
    "        # feature calculations\n",
    "        # feature calculations\n",
    "        \n",
    "        feature[source_num] = feat_val\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Your objective now is to apply your domain knowledge of astronomical signals to improve the provided machine learning model via feature engineering (and only feature engineering - do not attempt to use other models or change the model parameters).\n",
    "\n",
    "Below are 3 problems you should attempt to answer, but note - these problems are not necessarily independent and do not need to be completed sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**With a partner answer the following:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 3a**\n",
    "\n",
    "What is the best *simple* feature you can add to the model to improve the classification performance? \n",
    "\n",
    "Why simple? Because speed matters. If you need to classify $10^7$ LSST sources, you cannot run models that take several minutes to hours to run...\n",
    "\n",
    "*Note* - simple means can be executed on the full training set in a matter of seconds ($\\lesssim 100\\,\\mathrm{s}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 3b**\n",
    "\n",
    "What is the best individual feature you can add to the model to improve the classification performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Problem 3c**\n",
    "\n",
    "What combination of features provides the best classification accuracy for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Hint 1* - use `calc_cv_score` to measure the classification performance.\n",
    "\n",
    "*Hint 2* - if your efforts are limited by file read times, consider calculating multiple features within the function `calc_feature`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Hint 3* - you are in pairs for a reason. If you decide to attempt a very complicated feature that requires long runtimes, proceed with that calculation on one person's laptop, while working on some other feature calculation on the other person's laptop.\n",
    "\n",
    "*Hint 4* - be very careful about book keeping and variable names. You don't want to have to repeat a complex calculation because you accidentally renamed an active variable in your namespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Hint 5* - do not destroy any code that you write to calculate features. Ultimately, you will need to apply your feature calculations to a test set of new sources and it will be essential that the calculations are done in a reproducible way.\n",
    "\n",
    "*Hint 6* - pay attention to how long it takes for your feature calculations to run. If you have anything that takes $\\gtrsim 30\\,\\mathrm{min}$ let me know immediately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will compare answers at the end of the lecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "livereveal": {
   "height": 768,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "solarized",
   "width": 1024
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
